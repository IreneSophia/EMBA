# EMBA: using the Bayesian Brain to investigate the specificity of emotion recognition differences in autism and ADHD

## Face attention bias

Mutual social interactions require people to be aware of the affective state of their counterpart. An important source for this is facial expressions, which can be indicative of the emotions experienced by the other person. Individuals with autism spectrum disorder (ASD) often have difficulties with this function. Despite the extensive documentation of such differences, it is still unclear which processes underlie attenuated emotion recognition in ASD. In this project, we aim to use a prominent human brain theory called the Bayesian Brain to evaluate the impact of three mechanisms on emotion recognition in individuals with ASD at the neural and behavioural levels: (1) emotional face processing, (2) learning of associations between contextual cues and facial expressions associated with emotions, and (3) biased attention for faces. We also plan to include individuals with attention deficit hyperactivity disorder (ADHD) as clinical controls in addition to a sample of people with no neurodevelopmental disorder (NND). This allows us to determine whether differences in emotion recognition can be attributed to attentional deficits or are unspecific for the included developmental disorders. The results of this project will not only shed more light on the causes of deficits in emotion recognition in people with ASD, but also provide the basis for developing a model of the similarities and differences in processes of the Bayesian Brain in neurodevelopmental disorders.

In this repository, we will focus on the paradigm measuring face attention bias (FAB) with the dot probe paradigm. In this paradigm, participants are asked to indicate the location of a black square as fast as possible. Before the target square appears, two cues are presented for a short duration (200ms), one on the left and one on the right of the fixation cross. One cue is always a face while the other is an object. We will compare reaction times to target squares and saccades between the three groups (ADHD vs. ASD vs. no neurodevelopmental disorder, NND) as well as between two conditions (target appears on the side of the face vs. target appears on the side of the object). 

Participants also perform three additional paradigms: a facial emotion recognition task (FER), a probabilistic associative learning task (PAL) and a visual mismatch task (VMM). The preregistrations for this project are on [OSF](https://osf.io/znrht) and currently embargoed as the data collection is still ongoing. The preregistrations will be made public when manuscripts are submitted. 

This repository is a work in progress. The script are continuously augmented.
